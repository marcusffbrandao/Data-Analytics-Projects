{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ironhack - Data Analytics Bootcamp\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 3 - Data gathering processes\n",
    "\n",
    "Web Scraping and Databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Objectives\n",
    "\n",
    "The main objective of this project is to train your skills on obtaining data from different sources and safely storing it in a database. This will also help your develop skills in designing good process workflows.\n",
    "\n",
    "<img src=\"./objectives.jpg\" width=\"600px\"/>\n",
    "\n",
    "### Specific Objectives\n",
    "\n",
    "1. You will create one code to generate structured data from an API (or API wrapper);\n",
    "2. You will create another code to generate structured data from raw web-scraping (using beautiful-soup or any related tool you prefer);\n",
    "3. You will design and create your database with the structured data obtained;\n",
    "4. Do not forget to document the process.\n",
    "\n",
    "### Hints\n",
    "\n",
    "- Keep in mind that you can try to use this database later in the course. So it would be better if you choose something you are familiar with / you are interested in.\n",
    "- It would be lovely if you could relate both sources. That is, if you could later use both of your sources in the same context.\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "- The url of your Jupyter Notebook files on your GitHub.\n",
    "- The dump of your database.\n",
    "- [EXTRA] Draw the Entity-Relationship-Diagram of your database (https://app.quickdatabasediagrams.com/#/)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The project:\n",
    "\n",
    "### Chosing the  sources for this project:\n",
    "\n",
    "In this project we chose to create a dataframe containg information about the companies that are part of the Standard & Poor's 500, a stock market index that measures the stock performance of 500 large companies listed on stock exchanges in the United States.\n",
    "\n",
    "After doing some research, we decided to use the Yahoo Finance API¹ which, depite being discontinued,  is free, succinct and contains the quotes of most of the shares contained in S&P 500.\n",
    "\n",
    "However, this API presented some usage problems. There was a lack of information on some of the tickers, companies and quotes surveyed or the information was out of date.\n",
    "\n",
    "Therefore, we decided to get most of the information from another source by raw web-scraping. For this \n",
    "\n",
    "We did some research and decided to use Wikipedia², considering that this site has a good and reliable table with the information we needed about the S&P 500 companies. In addition, the table proved to be easy to be web-scraped.\n",
    "\n",
    "Finally we decided that the dataframe to be created would have the following information about the companies:\n",
    "\n",
    "- Symbol (or ticker);\n",
    "- Security (or name);\n",
    "- SEC filings;\n",
    "- GICS Sector;\n",
    "- GICS Sub Industry;\n",
    "- Headquarters Location;\n",
    "- Date first added;\n",
    "- CIK;\n",
    "- Founded;\n",
    "- 2019 third quarter quotes;\n",
    "- 2019 fourth quarter quotes;\n",
    "- 2020 first quarter quotes; and\n",
    "- 2020 second quarter quotes;\n",
    "\n",
    "### Sources used:\n",
    "\n",
    "1 - Yahoo Finance API:\n",
    "https://rapidapi.com/apidojo/api/yahoo-finance1 or\n",
    "https://english.api.rakuten.net/apidojo/api/yahoo-finance1\n",
    "\n",
    "2 - List of S&P 500 companies: https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\n",
    "\n",
    "### Steps taken:\n",
    "\n",
    "- Importing all the modules and libraries that we needed;\n",
    "- Saving the url to be scraped in the variable url_sp500;\n",
    "- Scraping the url using the Bautiful Sopu Python library;\n",
    "- Getting the first table from the scraped url;\n",
    "- Creating a pandas dataframe based on the scraped table;\n",
    "- Saving the tickers from the dataframe into a list to be used to get information from de Yahoo Finance API;\n",
    "- Searching for data in the Yahoo Finance API using the tickers from the created list;\n",
    "- Getting the open rates from Yahoo Finance API for the four desired quarters passing the initial dates of the quarters;\n",
    "- Using parallelization to get the open rates faster;\n",
    "- Getting the close rates from Yahoo Finance API for the last desired quarter passing the last date of the quarter;\n",
    "- Using parallelization to get the close rates faster;\n",
    "- Creating five columns in the sp500 dataframe with the obtained rates;\n",
    "- Creating a dataframe with all 18 the companies containing NaN to have a register of the companies without useful data;\n",
    "- Dropping lines in which all values are NaN;\n",
    "- Cleaning the 'Headquarters Location' column and creating lists of the 'states' and the 'countries':\n",
    "- Showing the Final dataframe containing 487 of the 505 S&P500 stocks; and\n",
    "- Exporting the final dataframe to a csv format file.\n",
    "\n",
    "### Problems faced:\n",
    "\n",
    "- The Yahoo Finance API appears to be out of date and is slow to work;\n",
    "- if the imputed date is a weekend day or a holiday, it will not return any value, such as the quote from the previous Friday or the last valid date recorded;\n",
    "- Yahoo Finance API does not return rates for some dates or some companies; and\n",
    "- 'Headquarters Location' column had data in different patterns and had to be cleaned. \n",
    "\n",
    "### Technologies used:\n",
    "\n",
    "- Python;\n",
    "- Pandas;\n",
    "- Numpy;\n",
    "- Beautiful Soup;\n",
    "- Yahoo Finance API;\n",
    "- Future;\n",
    "- Json;\n",
    "- Multiprocess;\n",
    "- Operator;\n",
    "- Regex;\n",
    "- Requests;\n",
    "- Tqdm; and\n",
    "- Urllib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Colaborators:\n",
    "\n",
    "- Marcus Brandão\n",
    "\n",
    "- Pelle Adamsen\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:16:42.008848Z",
     "start_time": "2020-07-12T21:16:42.004851Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:16:43.044684Z",
     "start_time": "2020-07-12T21:16:42.010833Z"
    }
   },
   "outputs": [],
   "source": [
    "# All the modules imported:\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from __future__ import division\n",
    "from multiprocess import Pool, cpu_count\n",
    "from operator import attrgetter\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import urllib.request\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:16:43.050614Z",
     "start_time": "2020-07-12T21:16:43.046651Z"
    }
   },
   "outputs": [],
   "source": [
    "# Url to be scrapped to get S&P 500 tickers and some data from Wikipedia:\n",
    "\n",
    "url_sp500 = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:16:44.642699Z",
     "start_time": "2020-07-12T21:16:43.052612Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scrapping the url using \"Beautiful Soup\":\n",
    "\n",
    "response_sp500 = requests.get(url_sp500)\n",
    "html_sp500 = response_sp500.content\n",
    "soup_sp500 = BeautifulSoup(html_sp500)\n",
    "soup_sp500.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:16:45.348598Z",
     "start_time": "2020-07-12T21:16:44.643674Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting the first table from the scraped url:\n",
    "soup_sp500.find_all('table', attrs={'id': 'constituents'})\n",
    "\n",
    "table = soup_sp500.find_all('table', attrs={'id': 'constituents'})[0]\n",
    "# table = soup.find('table', attrs={'class':'sortable wikitable'})\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:16:45.362587Z",
     "start_time": "2020-07-12T21:16:45.350594Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating the headers from the new dataframe from the header of the scraped table:\n",
    "\n",
    "headers = [header.text.strip() for header in table.find_all('th')]\n",
    "\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:16:45.486230Z",
     "start_time": "2020-07-12T21:16:45.364581Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting a list with all the table data from the scraped table:\n",
    "\n",
    "data = [data.text.strip() for data in table.find_all('td')]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:16:45.574994Z",
     "start_time": "2020-07-12T21:16:45.488225Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a pandas dataframe based on the scraped table:\n",
    "\n",
    "nrows = int(len(data)/9)\n",
    "ncols = 9\n",
    "sp500 = pd.DataFrame(np.array(data).reshape((nrows, ncols)), columns=headers)\n",
    "sp500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:16:45.645804Z",
     "start_time": "2020-07-12T21:16:45.576988Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting a list of the S&P500 tickers from the new table:\n",
    "\n",
    "sp500_tickers = sp500['Symbol'].values.tolist()\n",
    "\n",
    "print(sp500_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:16:47.775553Z",
     "start_time": "2020-07-12T21:16:45.647798Z"
    }
   },
   "outputs": [],
   "source": [
    "# Searching for data in the Yahoo Finance API using the tickers from the previos created table:\n",
    "\n",
    "yf_tickers = [yf.Ticker(i) for i in sp500_tickers]\n",
    "\n",
    "yf_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:16:47.783527Z",
     "start_time": "2020-07-12T21:16:47.776560Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting open rates from Yahoo Finance API:\n",
    "\n",
    "def get_open_rates(i):\n",
    "    try:\n",
    "        first_period_open = (i).history(period = '1d', start = '2019-7-1', end = '2019-7-2', rounding = True)['Open'].values.tolist()[0]\n",
    "    except:\n",
    "        first_period_open = None\n",
    "    try:\n",
    "        second_period_open = (i).history(period = '1d', start = '2019-10-1', end = '2019-10-2', rounding = True)['Open'].values.tolist()[0]\n",
    "    except:\n",
    "        second_period_open = None\n",
    "    try:\n",
    "        third_period_open = (i).history(period = '1d', start = '2020-1-2', end = '2020-1-3', rounding = True)['Open'].values.tolist()[0]\n",
    "    except:\n",
    "        third_period_open = None\n",
    "    try:\n",
    "        fourth_period_open = (i).history(period = '1d', start = '2020-4-1', end = '2020-4-2', rounding = True)['Open'].values.tolist()[0]\n",
    "    except:\n",
    "        fourth_period_open = None\n",
    "    return [first_period_open, second_period_open, third_period_open, fourth_period_open]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:19:14.666194Z",
     "start_time": "2020-07-12T21:16:47.785523Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pool to create a list with all open rates searched in the Yahoo Finance API:\n",
    "\n",
    "open_rates = []\n",
    "pool_2 = Pool(processes=cpu_count())\n",
    "open_rates = pool_2.map(get_open_rates, yf_tickers)\n",
    "\n",
    "pool_2.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:19:14.695085Z",
     "start_time": "2020-07-12T21:19:14.667181Z"
    }
   },
   "outputs": [],
   "source": [
    "# List with all open rates searched in the Yahoo Finance API:\n",
    "\n",
    "open_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:19:14.847909Z",
     "start_time": "2020-07-12T21:19:14.696075Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting close rates from Yahoo Finance API:\n",
    "\n",
    "def get_close_rates(i):\n",
    "    try:\n",
    "        fourth_quarter = (i).history(period = '1d', start = '2020-6-29', end = '2020-6-30', rounding = True)['Close'].values.tolist()[0]\n",
    "    except:\n",
    "        fourth_quarter = None\n",
    "    return fourth_quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:19:53.298748Z",
     "start_time": "2020-07-12T21:19:14.849869Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pool to create a list with all close rates searched in the Yahoo Finance API:\n",
    "\n",
    "close_rates = []\n",
    "pool_2 = Pool(processes=cpu_count())\n",
    "close_rates = pool_2.map(get_close_rates, yf_tickers)\n",
    "\n",
    "pool_2.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:19:53.309722Z",
     "start_time": "2020-07-12T21:19:53.299746Z"
    }
   },
   "outputs": [],
   "source": [
    "# List with all close rates searched in the Yahoo Finance API:\n",
    "close_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:19:53.422259Z",
     "start_time": "2020-07-12T21:19:53.311715Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(close_rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:19:53.497470Z",
     "start_time": "2020-07-12T21:19:53.427249Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating five columns in the sp500 dataframe with the obtained rates:\n",
    "\n",
    "sp500['2019_july_1'] = [i[0] for i in open_rates]\n",
    "sp500['2019_october_1'] = [i[1] for i in open_rates]\n",
    "sp500['2020_january_2'] = [i[2] for i in open_rates]\n",
    "sp500['2020_april_1'] = [i[3] for i in open_rates]\n",
    "sp500['2020_june_30'] = [i for i in close_rates]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:19:53.596504Z",
     "start_time": "2020-07-12T21:19:53.500462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualizing the sp500 dataframe:\n",
    "\n",
    "sp500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:19:53.698543Z",
     "start_time": "2020-07-12T21:19:53.598490Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe with all the rows containing NaN:\n",
    "\n",
    "sp500_nan = sp500[sp500.isna().any(axis=1)]\n",
    "sp500_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:19:53.784890Z",
     "start_time": "2020-07-12T21:19:53.699507Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping lines in which all values are NaN\n",
    "\n",
    "sp500 = sp500.dropna(how='any',axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:19:53.868978Z",
     "start_time": "2020-07-12T21:19:53.785887Z"
    }
   },
   "outputs": [],
   "source": [
    "sp500.head()\n",
    "len(sp500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:21:34.139606Z",
     "start_time": "2020-07-12T21:21:34.120654Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a deep copy of sp500 dataframe to treat the 'Headquarters Location' column:\n",
    "\n",
    "sp500_copy = sp500.copy()\n",
    "sp500_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:21:40.297417Z",
     "start_time": "2020-07-12T21:21:40.055067Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cleaning the 'Headquarters Location' column and creating lists of the 'states' and the 'countries':                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           #Cleaning the 'Headquarters Location' column:\n",
    "\n",
    "us_states = [\"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\n",
    "  \"Connecticut\",\"Delaware\",\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\"Illinois\",\n",
    "  \"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\n",
    "  \"Massachusetts\",\"Michigan\",\"Minnesota\",\"Mississippi\",\"Missouri\",\"Montana\",\n",
    "  \"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\"New Mexico\",\"New York\",\n",
    "  \"North Carolina\",\"North Dakota\",\"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\n",
    "  \"Rhode Island\",\"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\n",
    "  \"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\"]\n",
    "\n",
    "headquarters = sp500_copy['Headquarters Location'].values.tolist()\n",
    "location = []\n",
    "state = []\n",
    "country = []\n",
    "\n",
    "for i in headquarters:\n",
    "    i_splited = i.split(',')\n",
    "\n",
    "    a = i_splited[-2].strip()\n",
    "    b = i_splited[-1].strip()\n",
    "    a = re.sub(\"\\[.\\]\", \"\", a)\n",
    "    b = re.sub(\"\\[.\\]\", \"\", b)\n",
    "    if a == 'VA':\n",
    "        a = 'Virginia'\n",
    "    elif b == 'VA':\n",
    "        b = 'Virginia' \n",
    "    if b in us_states:\n",
    "        location.append(a)\n",
    "        state.append(b)\n",
    "        country.append('United States of America')\n",
    "        print(location, state, country)\n",
    "    elif a in us_states:\n",
    "        location.append(b)\n",
    "        state.append(a)\n",
    "        country.append('United States of America')\n",
    "        print(location, state, country)\n",
    "    else:\n",
    "        location.append(a)\n",
    "        state.append(a)\n",
    "        country.append(b)\n",
    "\n",
    "for n, i in enumerate(country):\n",
    "    if i == 'UK':\n",
    "        country[n] = 'United Kingdom'\n",
    "    elif i == 'Kingdom of the Netherlands':\n",
    "        country[n] = 'Netherlands'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:21:44.418719Z",
     "start_time": "2020-07-12T21:21:44.413763Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assigning the lists created above to the three new location columns:\n",
    "\n",
    "sp500_copy['Headquarters Location'] = location\n",
    "sp500_copy['State'] = state\n",
    "sp500_copy['Country'] = country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:21:46.585485Z",
     "start_time": "2020-07-12T21:21:46.578531Z"
    }
   },
   "outputs": [],
   "source": [
    "# Printing a list of the sp500_copy dataframe columns to reogarnize and rename them:\n",
    "\n",
    "list(sp500_copy.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:21:51.631015Z",
     "start_time": "2020-07-12T21:21:51.624032Z"
    }
   },
   "outputs": [],
   "source": [
    "# Renaming the columns:\n",
    "\n",
    "sp500_copy = sp500_copy[['Symbol', 'Security', 'SEC filings', 'GICS Sector', 'GICS Sub Industry', 'Headquarters Location','State', 'Country', 'Date first added', 'CIK', 'Founded', '2019_july_1', '2019_october_1', '2020_january_2', '2020_april_1', '2020_june_30']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T21:21:54.031527Z",
     "start_time": "2020-07-12T21:21:54.013570Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Final dataframe containing 498 of the 505 S&P500 stocks: \n",
    "\n",
    "sp500_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T23:15:40.636385Z",
     "start_time": "2020-07-12T23:15:40.597491Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exporting the final dataframe:\n",
    "\n",
    "sp500_copy.to_csv('./sp500.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
